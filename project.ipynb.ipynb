{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91af48b4-0ac7-44a7-9022-9c0172c36d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain langchain_community langchain_chroma pypdf ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8aa3932-656e-4ac7-8f96-41f79708cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbbd77-0a37-421a-b001-4cdd006c0977",
   "metadata": {},
   "source": [
    "# CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d0ad25-a51c-4d6e-9985-c012061e4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"documents\"\n",
    "CHROMA_PATH = \"chroma\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b952b7-2ac6-411a-b228-0bb06085545d",
   "metadata": {},
   "source": [
    "# LOAD DOCUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c7a1835-8b28-4618-8c49-89c35f770f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 120 document(s).\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(DATA_PATH, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "documents = loader.load()\n",
    "if not documents:\n",
    "    print(\"No PDF documents found. Please add your notes to the 'documents' folder.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(documents)} document(s).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d13757f-865c-4f19-b984-ff6ce9cefa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- List of Loaded Files ---\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "documents\\MACHINE LEARNING(R17A0534).pdf\n",
      "--------------------------\n",
      "Total files found: 120\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "\n",
    "DATA_PATH = \"documents\"\n",
    "\n",
    "loader = DirectoryLoader(DATA_PATH, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "\n",
    "print(\"--- List of Loaded Files ---\")\n",
    "for doc in documents:\n",
    "    print(doc.metadata['source'])\n",
    "print(\"--------------------------\")\n",
    "print(f\"Total files found: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c820be-0b49-4a89-a16f-3b9f967f7c31",
   "metadata": {},
   "source": [
    "# SPILT DOCUMENTS INTO SMALLER CHUNKS , SO THAT IT CAN BE MANAGED EASILY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7440b415-1750-47b4-b74c-3b02345769c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split documents into 337 chunks.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Split documents into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c8db5c-ab61-45b1-9006-1d7da1908542",
   "metadata": {},
   "source": [
    "# CREATING VECTOR DATABASE(CHROMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8192a2-e446-4b33-b673-415a06ba8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_documents():\n",
    "    print(\"Creating embeddings and storing in Chroma DB... (This may take a moment)\")\n",
    "    embeddings = OllamaEmbeddings(model=\"llama3\")\n",
    "    db = Chroma.from_documents(\n",
    "        documents=chunks, \n",
    "        embedding=embeddings, \n",
    "        persist_directory=CHROMA_PATH\n",
    "    )\n",
    "    print(f\"Successfully saved {len(chunks)} chunks to Chroma DB at '{CHROMA_PATH}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac3613-85b6-4cc1-9313-37afc8320f57",
   "metadata": {},
   "source": [
    "# COMPLETE THE INGESTION PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "755344b4-533d-4a79-84f0-c0b4bab0059e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 337 chunks to Chroma DB at 'chroma'.\n"
     ]
    }
   ],
   "source": [
    "ingest_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26f29b05-5b98-447d-ba7b-c6411e48adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39926c2c-e5e5-4a0a-901f-988f01e88df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query_rag(question_text):\n",
    "    print(\"Preparing to query the knowledge base...\")\n",
    "\n",
    "  \n",
    "    embeddings = OllamaEmbeddings(model='llama3')\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)\n",
    "\n",
    "    retriever = db.as_retriever()\n",
    "\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    Answer the question based only on the following context:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    ---\n",
    "\n",
    "    Answer the question based on the above context: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    " \n",
    "    model = Ollama(model=\"llama3\")\n",
    "\n",
    "  \n",
    "    chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    \n",
    "    print(\"Querying the AI...\")\n",
    "    response = chain.invoke(question_text)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2bf6eb-f152-4e9c-b7d1-7df79d44d105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to query the knowledge base...\n",
      "Querying the AI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_3896\\15567821.py:23: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  model = Ollama(model=\"llama3\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AI Answer ---\n",
      "\n",
      "There is no direct mention of what Machine Learning is in the provided context. However, it does mention \"Classification and regression tree tutorials\" and \"What is a CART in Machine Learning?\" which suggests that CART (Classification and Regression Tree) is a topic related to Machine Learning.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_question = \"What is Machine learning?\" \n",
    "\n",
    "\n",
    "answer = query_rag(my_question)\n",
    "\n",
    "\n",
    "print(\"\\n--- AI Answer ---\\n\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b97fcbd6-9940-4017-9a38-a852019710e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amit\\MINORPROJECT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af92d5-1977-47d1-92bc-57edfd5f503e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0e11d-3b6e-42cf-93fd-43887f145f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f9ecc-275d-4581-ac71-d09e08f0ec6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2403ce57-d1e8-42a0-ac58-0b825c94d783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1330c9d-b70a-4581-b083-f03025f8e374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
